{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unweighted Averages Over Datasets:\n",
      "----------------------------------------------------------------------\n",
      "Feature                        | Mean Corr |  Std Dev | Datasets\n",
      "----------------------------------------------------------------------\n",
      "IC9600                         |     0.877 |    0.057 |     16.0\n",
      "# of SAM segmentations         |     0.709 |    0.095 |     16.0\n",
      "MSG                            |     0.583 |    0.091 |     16.0\n",
      "symmetry                       |    -0.565 |    0.105 |     16.0\n",
      "M6                             |     0.549 |    0.100 |     16.0\n",
      "edge density                   |     0.548 |    0.085 |     16.0\n",
      "clutter                        |     0.545 |    0.111 |     16.0\n",
      "# of FC-CLIP classes           |     0.534 |    0.182 |     16.0\n",
      "MUC6                           |     0.530 |    0.148 |     16.0\n",
      "MUC7                           |     0.529 |    0.156 |     16.0\n",
      "MUC8                           |     0.525 |    0.161 |     16.0\n",
      "MUC5                           |     0.522 |    0.145 |     16.0\n",
      "MUC4                           |     0.512 |    0.143 |     16.0\n",
      "M10                            |     0.510 |    0.143 |     16.0\n",
      "M7                             |     0.510 |    0.129 |     16.0\n",
      "MUC3                           |     0.503 |    0.143 |     16.0\n",
      "MUC2                           |     0.495 |    0.144 |     16.0\n",
      "M4                             |    -0.494 |    0.134 |     16.0\n",
      "M1                             |     0.484 |    0.120 |     16.0\n",
      "M3                             |    -0.465 |    0.116 |     16.0\n",
      "MUC1                           |     0.391 |    0.140 |     16.0\n",
      "M2                             |    -0.323 |    0.129 |     16.0\n",
      "M11                            |    -0.304 |    0.109 |     16.0\n",
      "AMNet memorability             |    -0.205 |    0.194 |     16.0\n",
      "gemini surprise score          |     0.198 |    0.137 |     16.0\n",
      "M5                             |     0.185 |    0.147 |     16.0\n",
      "M9                             |     0.115 |    0.170 |     16.0\n",
      "\n",
      "Weighted Averages Based on Dataset Sample Sizes:\n",
      "------------------------------------------------------------------------------------------\n",
      "Feature                        |   Weighted Mean | Weighted Std |   Total Samples\n",
      "------------------------------------------------------------------------------------------\n",
      "IC9600                         |           0.894 |        0.060 |        11,494.0\n",
      "# of SAM segmentations         |           0.691 |        0.086 |        11,494.0\n",
      "MSG                            |           0.582 |        0.078 |        11,494.0\n",
      "M6                             |           0.565 |        0.078 |        11,494.0\n",
      "symmetry                       |          -0.553 |        0.086 |        11,494.0\n",
      "edge density                   |           0.547 |        0.080 |        11,494.0\n",
      "M4                             |          -0.522 |        0.111 |        11,494.0\n",
      "M7                             |           0.522 |        0.110 |        11,494.0\n",
      "# of FC-CLIP classes           |           0.505 |        0.172 |        11,494.0\n",
      "clutter                        |           0.500 |        0.077 |        11,494.0\n",
      "M1                             |           0.500 |        0.092 |        11,494.0\n",
      "MUC7                           |           0.476 |        0.098 |        11,494.0\n",
      "MUC8                           |           0.473 |        0.108 |        11,494.0\n",
      "MUC6                           |           0.472 |        0.082 |        11,494.0\n",
      "MUC5                           |           0.460 |        0.078 |        11,494.0\n",
      "MUC4                           |           0.447 |        0.080 |        11,494.0\n",
      "M10                            |           0.444 |        0.081 |        11,494.0\n",
      "M3                             |          -0.441 |        0.083 |        11,494.0\n",
      "MUC3                           |           0.436 |        0.083 |        11,494.0\n",
      "MUC2                           |           0.424 |        0.083 |        11,494.0\n",
      "M2                             |          -0.335 |        0.115 |        11,494.0\n",
      "MUC1                           |           0.332 |        0.092 |        11,494.0\n",
      "M11                            |          -0.252 |        0.083 |        11,494.0\n",
      "M5                             |           0.211 |        0.101 |        11,494.0\n",
      "AMNet memorability             |          -0.187 |        0.199 |        11,494.0\n",
      "gemini surprise score          |           0.164 |        0.110 |        11,494.0\n",
      "M9                             |           0.075 |        0.108 |        11,494.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karab\\AppData\\Local\\Temp\\ipykernel_19164\\3755367065.py:23: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  correlation, _ = stats.spearmanr(df['complexity'], df[column], nan_policy='omit')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import os\n",
    "\n",
    "def analyze_file_correlations(data, name=None):\n",
    "    \"\"\"Analyze Spearman correlations between 'complexity' and other features in a dataset.\"\"\"\n",
    "    try:\n",
    "        # If 'data' is a file path string, read the CSV\n",
    "        if isinstance(data, str):\n",
    "            df = pd.read_csv(data)\n",
    "        else:\n",
    "            df = data\n",
    "\n",
    "        if 'complexity' not in df.columns:\n",
    "            print(f\"\\nWarning: 'complexity' not found in {name or 'dataset'}\")\n",
    "            return None, 0\n",
    "\n",
    "        correlations = {}\n",
    "        for column in df.columns:\n",
    "            if column not in ['complexity', 'image_id']:\n",
    "                # Compute Spearman correlation (ignoring NaNs)\n",
    "                correlation, _ = stats.spearmanr(df['complexity'], df[column], nan_policy='omit')\n",
    "                if not np.isnan(correlation):\n",
    "                    correlations[column] = correlation\n",
    "\n",
    "        return correlations, len(df)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError processing {name or 'dataset'}: {e}\")\n",
    "        return None, 0\n",
    "\n",
    "def aggregate_correlations(all_files):\n",
    "    \"\"\"Aggregate correlations across all individual CSV files.\"\"\"\n",
    "    all_correlations = {}  # Dictionary to collect correlations per feature\n",
    "    all_datasets = []      # List to store (DataFrame, dataset_name) tuples\n",
    "\n",
    "    # Process each individual file\n",
    "    for file in all_files:\n",
    "        try:\n",
    "            df = pd.read_csv(file)\n",
    "            dataset_name = os.path.basename(file)\n",
    "            all_datasets.append((df, dataset_name))\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file}: {e}\")\n",
    "\n",
    "    # Iterate over every dataset\n",
    "    for data, name in all_datasets:\n",
    "        correlations, n_samples = analyze_file_correlations(data, name)\n",
    "        if correlations:\n",
    "            for feature, correlation in correlations.items():\n",
    "                # Append a tuple of (correlation, sample size, dataset name) for each feature\n",
    "                all_correlations.setdefault(feature, []).append((correlation, n_samples, name))\n",
    "\n",
    "    # Compute statistics for each feature across datasets\n",
    "    feature_stats = {}\n",
    "    total_datasets = len(all_datasets)\n",
    "    for feature, corr_list in all_correlations.items():\n",
    "        coverage = len(corr_list) / total_datasets\n",
    "        # Extract correlation values and sample sizes\n",
    "        corr_values = [item[0] for item in corr_list]\n",
    "        sample_sizes = [item[1] for item in corr_list]\n",
    "        total_samples = sum(sample_sizes)\n",
    "\n",
    "        # Unweighted (simple) average and standard deviation over datasets\n",
    "        mean_corr = np.mean(corr_values)\n",
    "        std_corr = np.std(corr_values) if len(corr_values) > 1 else 0\n",
    "\n",
    "        # Weighted average and weighted standard deviation\n",
    "        weights = [n / total_samples for n in sample_sizes]\n",
    "        weighted_mean = sum(c * w for c, w in zip(corr_values, weights))\n",
    "        weighted_var = sum(w * (x - weighted_mean) ** 2 for x, w in zip(corr_values, weights))\n",
    "        weighted_std = np.sqrt(weighted_var)\n",
    "\n",
    "        feature_stats[feature] = {\n",
    "            'mean_correlation': mean_corr,\n",
    "            'std_correlation': std_corr,\n",
    "            'weighted_mean_correlation': weighted_mean,\n",
    "            'weighted_std_correlation': weighted_std,\n",
    "            'num_datasets': len(corr_list),\n",
    "            'dataset_coverage': coverage,\n",
    "            'total_samples': total_samples\n",
    "        }\n",
    "\n",
    "    # Convert the dictionary to a DataFrame and add columns for absolute values for sorting\n",
    "    stats_df = pd.DataFrame.from_dict(feature_stats, orient='index')\n",
    "    stats_df['abs_mean_correlation'] = stats_df['mean_correlation'].abs()\n",
    "    stats_df['abs_weighted_mean_correlation'] = stats_df['weighted_mean_correlation'].abs()\n",
    "\n",
    "    return stats_df\n",
    "\n",
    "def print_unweighted_features_table(stats_df):\n",
    "    \"\"\"Print table of features using unweighted (simple average) statistics.\"\"\"\n",
    "    # Sort by absolute mean correlation (largest first)\n",
    "    sorted_features = stats_df.sort_values('abs_mean_correlation', ascending=False)\n",
    "    print(\"\\nUnweighted Averages Over Datasets:\")\n",
    "    print(\"-\" * 70)\n",
    "    print(f\"{'Feature':<30} | {'Mean Corr':>9} | {'Std Dev':>8} | {'Datasets':>8}\")\n",
    "    print(\"-\" * 70)\n",
    "    for feature, row in sorted_features.iterrows():\n",
    "        print(f\"{feature[:30]:<30} | {row['mean_correlation']:9.3f} | {row['std_correlation']:8.3f} | {row['num_datasets']:8}\")\n",
    "\n",
    "def print_weighted_features_table(stats_df):\n",
    "    \"\"\"Print table of features using weighted statistics based on dataset sample sizes.\"\"\"\n",
    "    # Sort by absolute weighted mean correlation (largest first)\n",
    "    sorted_features = stats_df.sort_values('abs_weighted_mean_correlation', ascending=False)\n",
    "    print(\"\\nWeighted Averages Based on Dataset Sample Sizes:\")\n",
    "    print(\"-\" * 90)\n",
    "    print(f\"{'Feature':<30} | {'Weighted Mean':>15} | {'Weighted Std':>12} | {'Total Samples':>15}\")\n",
    "    print(\"-\" * 90)\n",
    "    for feature, row in sorted_features.iterrows():\n",
    "        print(f\"{feature[:30]:<30} | {row['weighted_mean_correlation']:15.3f} | {row['weighted_std_correlation']:12.3f} | {row['total_samples']:15,}\")\n",
    "\n",
    "# ----------------------------\n",
    "# Example Usage\n",
    "# ----------------------------\n",
    "\n",
    "# List of individual CSV files containing features\n",
    "feature_files = [\n",
    "    \"RSIVL.csv\",\n",
    "    \"VISC.csv\",\n",
    "    \"IC9600 Abstract.csv\",\n",
    "    \"IC9600 Paintings.csv\",\n",
    "    \"IC9600 Scenes.csv\",\n",
    "    \"SAVOIAS Objects.csv\",\n",
    "    \"SAVOIAS Art.csv\",\n",
    "    \"SAVOIAS Scenes.csv\",\n",
    "    \"SAVOIAS Suprematism.csv\",\n",
    "    \"SAVOIAS Interior Design.csv\",\n",
    "    \"IC9600 Advertisement.csv\",\n",
    "    \"IC9600 Architecture.csv\",\n",
    "    \"IC9600 Person.csv\",\n",
    "    \"IC9600 Transport.csv\",\n",
    "    \"IC9600 Objects.csv\",\n",
    "    \"SVG.csv\"\n",
    "]\n",
    "\n",
    "# If your files are in a different folder, set the folder path here\n",
    "features_folder = \"../features\"\n",
    "feature_files = [os.path.join(features_folder, file) for file in feature_files]\n",
    "\n",
    "# Aggregate correlations over the individual files\n",
    "stats_df = aggregate_correlations(feature_files)\n",
    "\n",
    "# Print the two separate tables:\n",
    "print_unweighted_features_table(stats_df)\n",
    "print_weighted_features_table(stats_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ablation (Permutation Tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset                        |   symmetry |        MSG | Winner     | p-value   \n",
      "--------------------------------------------------------------------------------\n",
      "RSIVL.csv                      |     -0.708 |      0.721 | MSG        | 0.899     \n",
      "VISC.csv                       |     -0.579 |      0.573 | symmetry   | 0.843     \n",
      "IC9600 Abstract.csv            |     -0.663 |      0.705 | MSG        | 0.089     \n",
      "IC9600 Paintings.csv           |     -0.491 |      0.555 | MSG        | 0.011     \n",
      "IC9600 Scenes.csv              |     -0.649 |      0.664 | MSG        | 0.506     \n",
      "SAVOIAS Objects.csv            |     -0.379 |      0.397 | MSG        | 0.741     \n",
      "SAVOIAS Art.csv                |     -0.394 |      0.474 | MSG        | 0.079     \n",
      "SAVOIAS Scenes.csv             |     -0.498 |      0.492 | symmetry   | 0.912     \n",
      "SAVOIAS Suprematism.csv        |     -0.657 |      0.616 | symmetry   | 0.590     \n",
      "SAVOIAS Interior Design.csv    |     -0.709 |      0.666 | symmetry   | 0.574     \n",
      "IC9600 Advertisement.csv       |     -0.557 |      0.609 | MSG        | 0.053     \n",
      "IC9600 Architecture.csv        |     -0.531 |      0.588 | MSG        | 0.032     \n",
      "IC9600 Person.csv              |     -0.412 |      0.449 | MSG        | 0.126     \n",
      "IC9600 Transport.csv           |     -0.616 |      0.610 | symmetry   | 0.793     \n",
      "IC9600 Objects.csv             |     -0.534 |      0.537 | MSG        | 0.862     \n",
      "SVG.csv                        |     -0.656 |      0.666 | MSG        | 0.859     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'dataset': 'RSIVL.csv',\n",
       "  'correlation_x': np.float64(-0.7080792879673424),\n",
       "  'correlation_y': np.float64(0.7212428890838992),\n",
       "  'winner': 'MSG',\n",
       "  'p_value': np.float64(0.8991008991008991),\n",
       "  'n_samples': 49},\n",
       " {'dataset': 'VISC.csv',\n",
       "  'correlation_x': np.float64(-0.5787162827923932),\n",
       "  'correlation_y': np.float64(0.5733832054137853),\n",
       "  'winner': 'symmetry',\n",
       "  'p_value': np.float64(0.8431568431568431),\n",
       "  'n_samples': 800},\n",
       " {'dataset': 'IC9600 Abstract.csv',\n",
       "  'correlation_x': np.float64(-0.66282398604044),\n",
       "  'correlation_y': np.float64(0.7045076401915927),\n",
       "  'winner': 'MSG',\n",
       "  'p_value': np.float64(0.08891108891108891),\n",
       "  'n_samples': 1210},\n",
       " {'dataset': 'IC9600 Paintings.csv',\n",
       "  'correlation_x': np.float64(-0.4906154490346995),\n",
       "  'correlation_y': np.float64(0.5553231554035),\n",
       "  'winner': 'MSG',\n",
       "  'p_value': np.float64(0.01098901098901099),\n",
       "  'n_samples': 1200},\n",
       " {'dataset': 'IC9600 Scenes.csv',\n",
       "  'correlation_x': np.float64(-0.6492394409976632),\n",
       "  'correlation_y': np.float64(0.6644264225537926),\n",
       "  'winner': 'MSG',\n",
       "  'p_value': np.float64(0.5064935064935064),\n",
       "  'n_samples': 1216},\n",
       " {'dataset': 'SAVOIAS Objects.csv',\n",
       "  'correlation_x': np.float64(-0.37915955722181055),\n",
       "  'correlation_y': np.float64(0.3970312010891752),\n",
       "  'winner': 'MSG',\n",
       "  'p_value': np.float64(0.7412587412587412),\n",
       "  'n_samples': 200},\n",
       " {'dataset': 'SAVOIAS Art.csv',\n",
       "  'correlation_x': np.float64(-0.3942065856037594),\n",
       "  'correlation_y': np.float64(0.47405554236933184),\n",
       "  'winner': 'MSG',\n",
       "  'p_value': np.float64(0.07892107892107893),\n",
       "  'n_samples': 420},\n",
       " {'dataset': 'SAVOIAS Scenes.csv',\n",
       "  'correlation_x': np.float64(-0.49759199357576944),\n",
       "  'correlation_y': np.float64(0.4917797496517379),\n",
       "  'winner': 'symmetry',\n",
       "  'p_value': np.float64(0.9120879120879121),\n",
       "  'n_samples': 200},\n",
       " {'dataset': 'SAVOIAS Suprematism.csv',\n",
       "  'correlation_x': np.float64(-0.6574136487698988),\n",
       "  'correlation_y': np.float64(0.6157599852852585),\n",
       "  'winner': 'symmetry',\n",
       "  'p_value': np.float64(0.5904095904095904),\n",
       "  'n_samples': 100},\n",
       " {'dataset': 'SAVOIAS Interior Design.csv',\n",
       "  'correlation_x': np.float64(-0.7091541092468985),\n",
       "  'correlation_y': np.float64(0.6658144128915023),\n",
       "  'winner': 'symmetry',\n",
       "  'p_value': np.float64(0.5744255744255744),\n",
       "  'n_samples': 100},\n",
       " {'dataset': 'IC9600 Advertisement.csv',\n",
       "  'correlation_x': np.float64(-0.5565472304577486),\n",
       "  'correlation_y': np.float64(0.6093213172722525),\n",
       "  'winner': 'MSG',\n",
       "  'p_value': np.float64(0.052947052947052944),\n",
       "  'n_samples': 1060},\n",
       " {'dataset': 'IC9600 Architecture.csv',\n",
       "  'correlation_x': np.float64(-0.5307501712605396),\n",
       "  'correlation_y': np.float64(0.5881499282598349),\n",
       "  'winner': 'MSG',\n",
       "  'p_value': np.float64(0.03196803196803197),\n",
       "  'n_samples': 1153},\n",
       " {'dataset': 'IC9600 Person.csv',\n",
       "  'correlation_x': np.float64(-0.41218813334931964),\n",
       "  'correlation_y': np.float64(0.4493459323091273),\n",
       "  'winner': 'MSG',\n",
       "  'p_value': np.float64(0.1258741258741259),\n",
       "  'n_samples': 1200},\n",
       " {'dataset': 'IC9600 Transport.csv',\n",
       "  'correlation_x': np.float64(-0.6163066638604741),\n",
       "  'correlation_y': np.float64(0.6103802773684348),\n",
       "  'winner': 'symmetry',\n",
       "  'p_value': np.float64(0.7932067932067932),\n",
       "  'n_samples': 1186},\n",
       " {'dataset': 'IC9600 Objects.csv',\n",
       "  'correlation_x': np.float64(-0.5341196498208817),\n",
       "  'correlation_y': np.float64(0.5374292146284197),\n",
       "  'winner': 'MSG',\n",
       "  'p_value': np.float64(0.8621378621378621),\n",
       "  'n_samples': 1200},\n",
       " {'dataset': 'SVG.csv',\n",
       "  'correlation_x': np.float64(-0.656044595951233),\n",
       "  'correlation_y': np.float64(0.666075400998876),\n",
       "  'winner': 'MSG',\n",
       "  'p_value': np.float64(0.8591408591408591),\n",
       "  'n_samples': 200}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import os\n",
    "\n",
    "def calculate_correlations(df, dataset_name, feature_x, feature_y, n_permutations=1000):\n",
    "    \"\"\"\n",
    "    Calculate Spearman correlations of `feature_x` and `feature_y` with `complexity`.\n",
    "    Perform a permutation test to evaluate statistical significance.\n",
    "    \"\"\"\n",
    "    if 'complexity' not in df.columns:\n",
    "        print(f\"Warning: 'complexity' column not found in {dataset_name}\")\n",
    "        return None\n",
    "\n",
    "    corr_x, _ = stats.spearmanr(df['complexity'], df[feature_x], nan_policy='omit')\n",
    "    corr_y, _ = stats.spearmanr(df['complexity'], df[feature_y], nan_policy='omit')\n",
    "\n",
    "    # Permutation test: Compute p-value\n",
    "    actual_diff = abs(corr_x) - abs(corr_y)\n",
    "    permuted_diffs = [\n",
    "        abs(stats.spearmanr(df['complexity'].sample(frac=1).values, df[feature_x], nan_policy='omit')[0]) -\n",
    "        abs(stats.spearmanr(df['complexity'].sample(frac=1).values, df[feature_y], nan_policy='omit')[0])\n",
    "        for _ in range(n_permutations)\n",
    "    ]\n",
    "\n",
    "    p_value = (np.sum(np.abs(permuted_diffs) >= np.abs(actual_diff)) + 1) / (n_permutations + 1)\n",
    "    winner = feature_x if abs(corr_x) > abs(corr_y) else feature_y if abs(corr_y) > abs(corr_x) else \"Tie\"\n",
    "\n",
    "    return {\n",
    "        'dataset': dataset_name,\n",
    "        'correlation_x': corr_x,\n",
    "        'correlation_y': corr_y,\n",
    "        'winner': winner,\n",
    "        'p_value': p_value,\n",
    "        'n_samples': len(df)\n",
    "    }\n",
    "\n",
    "def compare_feature_correlations(file_paths, feature_x, feature_y, base_path=\"\", n_permutations=1000):\n",
    "    \"\"\"\n",
    "    Compare correlations of two features across multiple datasets.\n",
    "    Prints and returns the correlation results.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    print(\"\\n{:<30} | {:>10} | {:>10} | {:<10} | {:<10}\".format(\"Dataset\", feature_x, feature_y, \"Winner\", \"p-value\"))\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    for file in file_paths:\n",
    "        try:\n",
    "            df = pd.read_csv(os.path.join(base_path, file))\n",
    "            dataset_name = os.path.basename(file).replace('_features.csv', '')\n",
    "            result = calculate_correlations(df, dataset_name, feature_x, feature_y, n_permutations)\n",
    "            if result:\n",
    "                results.append(result)\n",
    "                print(\"{:<30} | {:>10.3f} | {:>10.3f} | {:<10} | {:<10.3f}\".format(\n",
    "                    result['dataset'], result['correlation_x'], result['correlation_y'], result['winner'], result['p_value']\n",
    "                ))\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file}: {e}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# ----------------------------\n",
    "# Example Usage\n",
    "# ----------------------------\n",
    "\n",
    "feature_files = [\n",
    "    \"RSIVL.csv\",\n",
    "    \"VISC.csv\",\n",
    "    \"IC9600 Abstract.csv\",\n",
    "    \"IC9600 Paintings.csv\",\n",
    "    \"IC9600 Scenes.csv\",\n",
    "    \"SAVOIAS Objects.csv\",\n",
    "    \"SAVOIAS Art.csv\",\n",
    "    \"SAVOIAS Scenes.csv\",\n",
    "    \"SAVOIAS Suprematism.csv\",\n",
    "    \"SAVOIAS Interior Design.csv\",\n",
    "    \"IC9600 Advertisement.csv\",\n",
    "    \"IC9600 Architecture.csv\",\n",
    "    \"IC9600 Person.csv\",\n",
    "    \"IC9600 Transport.csv\",\n",
    "    \"IC9600 Objects.csv\",\n",
    "    \"SVG.csv\"\n",
    "]\n",
    "\n",
    "features_folder = \"../features\"\n",
    "feature_files = [os.path.join(features_folder, file) for file in feature_files]\n",
    "\n",
    "\n",
    "# Run correlation comparison\n",
    "results = compare_feature_correlations(feature_files, 'symmetry', 'MSG')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
